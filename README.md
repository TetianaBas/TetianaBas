# ğŸ‘‹ Hi, I'm Tanya!

I'm an aspiring **Machine Learning Researcher** with an interest in **Large Language Models (LLMs)** and their applications across multiple domains. My primary research focuses include:

- ğŸ§  **Intersection of LLMs and Graph Neural Networks (GNNs)**
- ğŸŒ **Multilingual LLMs** and understanding the complex linguistic structures behind multiple languages
- ğŸ”§ **Parameter-efficient fine-tuning** techniques to optimize model performance without overwhelming computational resources
- ğŸ“‰ **Solving data scarcity problems** through creative use of LLMs and transfer learning approaches
- âš–ï¸ **Bias evaluation and model debiasing** â€” striving for fairness and inclusivity in AI models

I love working with different architectures and enjoy **implementing ML models from scratch**, as it allows me to deeply understand the underlying mechanics of each technique.

## ğŸŒŸ Why Language?

Before LLMs became mainstream, I was already fascinated by the **logical structures** of language and how they could be modeled computationally. Having learned **6 languages**, I bring a unique perspective on **language as a concept**â€”each language reveals different structures, nuances, and modes of thought. This personal experience fuels my passion for developing better and more inclusive language models.

## ğŸŒ Global Perspective

Iâ€™ve had the opportunity to live, study, and work in multiple countries, gaining diverse perspectives and experiences:

ğŸ‡ºğŸ‡¸ ğŸ‡¬ğŸ‡§ ğŸ‡ºğŸ‡¦ ğŸ‡¹ğŸ‡¼ ğŸ‡°ğŸ‡· ğŸ‡®ğŸ‡³ ğŸ‡¨ğŸ‡¦ ğŸ‡©ğŸ‡ª

These experiences shape my approach to research, collaboration, and solving global problems using machine learning.
