# 👋 Hi, I'm Tanya!

I'm an aspiring **Machine Learning Researcher** with an interest in **Large Language Models (LLMs)** and their applications across multiple domains. My primary research focuses include:

- 🧠 **Intersection of LLMs and Graph Neural Networks (GNNs)**
- 🌍 **Multilingual LLMs** and understanding the complex linguistic structures behind multiple languages
- 🔧 **Parameter-efficient fine-tuning** techniques to optimize model performance without overwhelming computational resources
- 📉 **Solving data scarcity problems** through creative use of LLMs and transfer learning approaches
- ⚖️ **Bias evaluation and model debiasing** — striving for fairness and inclusivity in AI models

I love working with different architectures and enjoy **implementing ML models from scratch**, as it allows me to deeply understand the underlying mechanics of each technique.

## 🌟 Why Language?

Before LLMs became mainstream, I was already fascinated by the **logical structures** of language and how they could be modeled computationally. Having learned **6 languages**, I bring a unique perspective on **language as a concept**—each language reveals different structures, nuances, and modes of thought. This personal experience fuels my passion for developing better and more inclusive language models.

## 🌎 Global Perspective

I’ve had the opportunity to live, study, and work in multiple countries, gaining diverse perspectives and experiences:

🇺🇸 🇬🇧 🇺🇦 🇹🇼 🇰🇷 🇮🇳 🇨🇦 🇩🇪

These experiences shape my approach to research, collaboration, and solving global problems using machine learning.
